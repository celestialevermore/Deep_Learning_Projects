{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치 초기화\n",
    "\n",
    "좋은 가중치 초기화 조건\n",
    "- 값이 동일해서는 안된다.\n",
    "\n",
    "- 충분히 작아야 한다.\n",
    "\n",
    "- 적당한 분산(혹은 표준편차)를 취해야함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "값이 갑자기 너무 커지거나, 너무 작아지면 제대로 반영이 안됨. 충분한 값을 취해야한다.\n",
    "\n",
    "\n",
    "그리고 가중치 값이 동일해져버리면 Layer 한 층을 통과했을 때 그대로 나와버림. 의미가 없음. \n",
    "\n",
    "\"적당한 분산(또는 표준편차)를 가져야 한다. \n",
    "\n",
    "-> 표준 정규 분포를 이룰 수 있도록 E(0,1)로 맞춰줄 수 있도록.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균이 1이고 표준편차가 1인 표준 정규분포에서 난수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.random.normal(loc=0.0,scale=10,size=(100,100))\n",
    "#loc : 평균 딱 가운데 \n",
    "#scale : 표준편차\n",
    "#분포를 2차원 배열로 만들어준다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-19.16714524  -2.04982538  17.14888359 ...   7.32663432  -4.74297256\n",
      "   11.87551288]\n",
      " [  9.46760297 -18.30262263   7.95218806 ...   7.06129724  -5.12909793\n",
      "   -5.8233991 ]\n",
      " [-10.48849103  11.56284307   8.31746253 ...   1.68959293   2.85061399\n",
      "   18.7445445 ]\n",
      " ...\n",
      " [  1.42952248   5.41829115   1.82359811 ...   4.16028476   2.88421644\n",
      "   -6.99992283]\n",
      " [ -1.89094503  15.52190024   3.51777611 ... -14.46431042  -6.7650828\n",
      "    7.59229776]\n",
      " [ -6.20880191   6.31577816  -9.64318486 ...   5.77078503  -9.92875607\n",
      "  -16.01921239]]\n"
     ]
    }
   ],
   "source": [
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01780125651987748\n",
      "9.875195278086878\n",
      "178.01256519877478\n"
     ]
    }
   ],
   "source": [
    "print(numbers.mean())\n",
    "print(numbers.std())\n",
    "print(numbers.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier Glorot Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력 노드와 출력 노드의 개수를 감안하여, 동적으로 Weight 초기화를 수행합니다. \n",
    "\n",
    "- 표준편차를 동적으로 계산한다. 1은 너무 크고, 0은 너무 작으니까. \n",
    "  - glorot_normal : 표준편차 = sqrt(2/fan in + fan out) Normal Distribution(평균=0,표준편차)\n",
    "  - glorot_uniform : 한도값 = sqrt(6/fan in + fan out) Uniform Distribution(-한도값, +한도값)\n",
    "  - fan in : 입력 노드의 개수, fan out : 출력 노드의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavier initialization - 정규분포(glorot_normal), 균일 분포(glorot_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale : 0.3333333333333333\n",
      "정규 분포를 적용한 결과\n",
      "[[-0.12831826  0.0097353  -0.38093036 ... -0.7067343  -0.41487129\n",
      "  -0.10592604]\n",
      " [ 0.02672043  0.41441784  0.81202648 ... -0.38415879 -0.26519038\n",
      "   0.28938182]\n",
      " [ 0.11726333 -0.22766836  0.08704459 ... -0.23625923  0.42288567\n",
      "   0.06086279]\n",
      " ...\n",
      " [-0.32961586  0.05758454  0.22843887 ...  0.15307249  0.41670941\n",
      "  -0.08450769]\n",
      " [-0.88312689  0.64174859  0.13252679 ... -0.21308911  0.06427967\n",
      "  -0.39231559]\n",
      " [-0.61679504 -0.35294906 -0.36556336 ...  0.44190158  0.31226571\n",
      "   0.33347067]]\n",
      "weight mean: 0.0017018880973459123 std : 0.3360896247566897 sum : 17.018880973459122\n"
     ]
    }
   ],
   "source": [
    "#glorot_normal\n",
    "fan_in = 10\n",
    "fan_out = 8 \n",
    "\n",
    "scale_value = np.sqrt(2/(fan_in+fan_out))\n",
    "\n",
    "print('scale :',scale_value)\n",
    "\n",
    "weights = np.random.normal(loc=0.0,scale=scale_value,size=(100,100))\n",
    "print('정규 분포를 적용한 결과')\n",
    "print(weights)\n",
    "print('weight mean:',weights.mean(),'std :',weights.std(),'sum :',weights.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "값 자체의 변동성이 상당히 작다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit : 0.5773502691896257\n",
      "[[ 0.06145095  0.09230575  0.18466608 ... -0.1360279  -0.47029074\n",
      "  -0.56911226]\n",
      " [-0.2705147   0.55460174  0.32424453 ...  0.08005308  0.46038852\n",
      "   0.09842914]\n",
      " [ 0.57484742  0.09083533 -0.1892746  ... -0.4192025   0.31062211\n",
      "  -0.28858728]\n",
      " ...\n",
      " [-0.56142657 -0.04917358  0.02518191 ... -0.14744548  0.10334592\n",
      "  -0.09432805]\n",
      " [ 0.02424431 -0.16892356 -0.42902304 ... -0.25492714 -0.22617856\n",
      "  -0.08330149]\n",
      " [ 0.20186187 -0.54518329 -0.57523688 ... -0.34073057  0.55717714\n",
      "  -0.33829864]]\n",
      "weights mean : 0.0019868775472380697 std : 0.33240782110738315 sum : 19.868775472380698\n"
     ]
    }
   ],
   "source": [
    "#glorot_uniform \n",
    "\n",
    "fan_in = 10\n",
    "fan_out = 8\n",
    "limit = np.sqrt(6/(fan_in+fan_out))\n",
    "\n",
    "print('limit :',limit)\n",
    "\n",
    "weights = np.random.uniform(-1*limit,limit,size=(100,100))\n",
    "\n",
    "print(weights)\n",
    "\n",
    "print('weights mean :',weights.mean(),'std :',weights.std(),'sum :',weights.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He Initialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xavier 방식보다 relu에 최적화된 가중치 초기화를 제안하였습니다. \n",
    "  - he_uniform : 한도값 = sqrt(6/(fan in))\n",
    "  - he_normal : 표준편차 = sqrt(2/(fan in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale : 0.7745966692414834\n",
      "[[ 0.77405102  0.11585457 -0.75571387 ...  0.6974583   0.49071249\n",
      "   0.5467341 ]\n",
      " [-0.90638684  0.1456844   1.18343762 ...  0.19147449 -0.3242598\n",
      "   0.50419185]\n",
      " [ 0.9686451   1.35773403 -0.12847129 ... -0.94475471 -0.35035426\n",
      "  -0.3843233 ]\n",
      " ...\n",
      " [ 0.71595984 -0.99911466  0.90384929 ...  0.99400181  0.27375283\n",
      "  -0.10264032]\n",
      " [-1.06702045 -0.74523291 -0.1738419  ... -1.38681005 -0.34823912\n",
      "  -0.53422177]\n",
      " [-0.58991242 -0.17369864  0.3554933  ...  0.29594695  1.98067656\n",
      "   0.86567533]]\n",
      "weight mean : -0.01114112137225591 std : 0.7784586609374436 sum : -111.4112137225591\n"
     ]
    }
   ],
   "source": [
    "# he unifrom \n",
    "fan_in = 10\n",
    "fan_out = 8\n",
    "\n",
    "scale_value = np.sqrt(6/fan_in)\n",
    "\n",
    "print('scale :',scale_value)\n",
    "\n",
    "weights = np.random.normal(loc=0.0,scale=scale_value,size=(100,100))\n",
    "print(weights)\n",
    "\n",
    "print('weight mean :',weights.mean(),'std :',weights.std(),'sum :',weights.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight 초기화를 He Normal로 변경 후 성능 검증\n",
    "\n",
    "- Keras Conv2D의 기본 weight 초기화는 glorot_uniform입니다. 이를 he_normal로 변경 후 동일 모델로 성능을 비교합니다.\n",
    "\n",
    "- label은 원핫 인코딩을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "def get_preprocessed_data(images,labels):\n",
    "\n",
    "    #학습과 테스트 이미지 array를 0~1 사이 값으로 scale 및 float32형으로 변형\n",
    "    images = np.array(images/255.0,dtype=np.float32)\n",
    "    labels = np.array(labels,dtype=np.float32)\n",
    "    labels = labels.squeeze()\n",
    "\n",
    "    return images,labels\n",
    "\n",
    "\n",
    "\n",
    "#0 ~ 1 사이값 float32로 변경하는 함수를 호출한 뒤, OHE를 적용\n",
    "\n",
    "def get_preprocessed_ohe(images,labels):\n",
    "    images,labels = get_preprocessed_data(images,labels)\n",
    "    #OHE 적용\n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images,oh_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=cifar10.load_data()\n",
    "\n",
    "train_images,train_oh_labels = get_preprocessed_ohe(train_images,train_labels)\n",
    "test_images,test_oh_labels = get_preprocessed_ohe(test_images,test_labels)\n",
    "\n",
    "print(train_images.shape,train_oh_labels.shape,test_images.shape,test_oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 300)               614700    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 904,718\n",
      "Trainable params: 904,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 23:52:35.493990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.494173: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.494255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.545598: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.545689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.545756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-03 23:52:35.545774: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-03 23:52:35.546432: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input,Dense,Conv2D,Dropout,Flatten,Activation,MaxPooling2D,GlobalAveragePooling2D \n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "#들어오는건 커널 인풋 텐서 가로 세로 사이즈가 32,이고 RGB이니까 총 세 개\n",
    "#3차원이 들어오지만 모델은 저절로 4차원으로 인식될 예정 \n",
    "\n",
    "\n",
    "x = Conv2D(filters = 32,kernel_size=(3,3),padding = 'same',activation='relu',kernel_initializer='he_normal')(input_tensor)\n",
    "x = Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "x = Conv2D(filters=64,kernel_size=3,padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer='he_normal')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',kernel_initializer='he_normal')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "#cifar label클래스가 10개이므로, 마지막 classification 의 Dense Layer units의 개수는 10\n",
    "\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300,activation='relu',name='fc1')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "\n",
    "output = Dense(10,activation='softmax',name='output')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 23:54:06.180558: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "665/665 [==============================] - 41s 60ms/step - loss: 1.5937 - accuracy: 0.4136 - val_loss: 1.2855 - val_accuracy: 0.5339\n",
      "Epoch 2/30\n",
      "665/665 [==============================] - 37s 56ms/step - loss: 1.1173 - accuracy: 0.6029 - val_loss: 0.9237 - val_accuracy: 0.6664\n",
      "Epoch 3/30\n",
      "665/665 [==============================] - 38s 57ms/step - loss: 0.9132 - accuracy: 0.6781 - val_loss: 0.9045 - val_accuracy: 0.6813\n",
      "Epoch 4/30\n",
      "665/665 [==============================] - 40s 60ms/step - loss: 0.7953 - accuracy: 0.7197 - val_loss: 0.7587 - val_accuracy: 0.7356\n",
      "Epoch 5/30\n",
      "665/665 [==============================] - 40s 60ms/step - loss: 0.7063 - accuracy: 0.7522 - val_loss: 0.7027 - val_accuracy: 0.7559\n",
      "Epoch 6/30\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.6375 - accuracy: 0.7756 - val_loss: 0.6859 - val_accuracy: 0.7607\n",
      "Epoch 7/30\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.5835 - accuracy: 0.7956 - val_loss: 0.6291 - val_accuracy: 0.7829\n",
      "Epoch 8/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.5490 - accuracy: 0.8080 - val_loss: 0.6676 - val_accuracy: 0.7711\n",
      "Epoch 9/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.5066 - accuracy: 0.8228 - val_loss: 0.6286 - val_accuracy: 0.7856\n",
      "Epoch 10/30\n",
      "665/665 [==============================] - 44s 67ms/step - loss: 0.4613 - accuracy: 0.8353 - val_loss: 0.6398 - val_accuracy: 0.7848\n",
      "Epoch 11/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.4308 - accuracy: 0.8468 - val_loss: 0.6350 - val_accuracy: 0.7811\n",
      "Epoch 12/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.4154 - accuracy: 0.8517 - val_loss: 0.6267 - val_accuracy: 0.7855\n",
      "Epoch 13/30\n",
      "665/665 [==============================] - 44s 67ms/step - loss: 0.3955 - accuracy: 0.8587 - val_loss: 0.6339 - val_accuracy: 0.7828\n",
      "Epoch 14/30\n",
      "665/665 [==============================] - 44s 65ms/step - loss: 0.3663 - accuracy: 0.8706 - val_loss: 0.6517 - val_accuracy: 0.7833\n",
      "Epoch 15/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.3572 - accuracy: 0.8736 - val_loss: 0.6269 - val_accuracy: 0.7929\n",
      "Epoch 16/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.3496 - accuracy: 0.8758 - val_loss: 0.6435 - val_accuracy: 0.7933\n",
      "Epoch 17/30\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.3277 - accuracy: 0.8848 - val_loss: 0.6733 - val_accuracy: 0.7887\n",
      "Epoch 18/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.3150 - accuracy: 0.8887 - val_loss: 0.7029 - val_accuracy: 0.7859\n",
      "Epoch 19/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.3020 - accuracy: 0.8924 - val_loss: 0.6501 - val_accuracy: 0.7967\n",
      "Epoch 20/30\n",
      "665/665 [==============================] - 44s 67ms/step - loss: 0.2926 - accuracy: 0.8984 - val_loss: 0.7445 - val_accuracy: 0.7900\n",
      "Epoch 21/30\n",
      "665/665 [==============================] - 44s 67ms/step - loss: 0.2786 - accuracy: 0.9020 - val_loss: 0.6953 - val_accuracy: 0.7916\n",
      "Epoch 22/30\n",
      "665/665 [==============================] - 45s 67ms/step - loss: 0.2800 - accuracy: 0.9028 - val_loss: 0.6695 - val_accuracy: 0.7951\n",
      "Epoch 23/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.2729 - accuracy: 0.9037 - val_loss: 0.7237 - val_accuracy: 0.7876\n",
      "Epoch 24/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.2698 - accuracy: 0.9056 - val_loss: 0.7104 - val_accuracy: 0.7913\n",
      "Epoch 25/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.2704 - accuracy: 0.9063 - val_loss: 0.6775 - val_accuracy: 0.7920\n",
      "Epoch 26/30\n",
      "665/665 [==============================] - 45s 67ms/step - loss: 0.2601 - accuracy: 0.9076 - val_loss: 0.7032 - val_accuracy: 0.7877\n",
      "Epoch 27/30\n",
      "665/665 [==============================] - 44s 67ms/step - loss: 0.2503 - accuracy: 0.9125 - val_loss: 0.7152 - val_accuracy: 0.7951\n",
      "Epoch 28/30\n",
      "665/665 [==============================] - 45s 67ms/step - loss: 0.2474 - accuracy: 0.9151 - val_loss: 0.7465 - val_accuracy: 0.7931\n",
      "Epoch 29/30\n",
      "665/665 [==============================] - 44s 66ms/step - loss: 0.2474 - accuracy: 0.9150 - val_loss: 0.7142 - val_accuracy: 0.8016\n",
      "Epoch 30/30\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.2405 - accuracy: 0.9159 - val_loss: 0.7626 - val_accuracy: 0.7971\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=train_images,y=train_oh_labels,batch_size=64,epochs=30,validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b45cb9130eebfe057782ef3fcf20eb5ae5c81aa7ea2b32ada9dc8e4e9a15b7c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
