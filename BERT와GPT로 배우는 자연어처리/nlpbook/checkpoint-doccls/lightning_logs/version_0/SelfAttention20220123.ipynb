{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([ \n",
    "    [1.0,0.0,1.0,0.0],\n",
    "    [0.0,2.0,0.0,2.0],\n",
    "    [1.0,1.0,1.0,1.0],\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "w_query=torch.tensor([ \n",
    "    [1.0,0.0,1.0],\n",
    "    [1.0,0.0,0.0],\n",
    "    [0.0,0.0,1.0],\n",
    "    [0.0,1.0,1.0]\n",
    "])\n",
    "\n",
    "w_key=torch.tensor([ \n",
    "    [0.0,0.0,1.0],\n",
    "    [1.0,1.0,0.0],\n",
    "    [0.0,1.0,0.0],\n",
    "    [1.0,1.0,0.0]\n",
    "])\n",
    "\n",
    "w_value = torch.tensor([ \n",
    "    [0.0,2.0,0.0], \n",
    "    [0.0,3.0,0.0],\n",
    "    [1.0,0.0,3.0],\n",
    "    [1.0,1.0,0.0]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드는 입력 벡터 시퀀스로\n",
    "\n",
    "\n",
    "쿼리,키,밸류 벡터들을 만드는 부분입니다.\n",
    "\n",
    "torch.matlul은 행렬곱을 수행하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = torch.matmul(x,w_key)\n",
    "querys = torch.matmul(x,w_query)\n",
    "values = torch.matmul(x,w_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드는 앞 코드에서 만든 쿼리 벡터(querys)와 키 벡터(keys)를 행렬곱해서\n",
    "\n",
    "어텐션 스코어를 만드는 과정입니다. \n",
    "\n",
    "keys.T는 키 벡터들을 전치한 행렬입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.matmul(querys,keys.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  4.],\n",
       "        [ 4., 16., 12.],\n",
       "        [ 4., 12., 10.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from torch.nn.functional import softmax \n",
    "\n",
    "key_dim_sqrt = np.sqrt(keys.shape[-1])\n",
    "\n",
    "attn_probs = softmax(attn_scores / key_dim_sqrt,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3613e-01, 4.3194e-01, 4.3194e-01],\n",
       "        [8.9045e-04, 9.0884e-01, 9.0267e-02],\n",
       "        [7.4449e-03, 7.5471e-01, 2.3785e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드는 앞에서 구한 소프트맥스 확률과 밸류 벡터들을 가중합하는 과정을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_values = torch.matmul(attn_probs,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8639, 6.3194, 1.7042],\n",
       "        [1.9991, 7.8141, 0.2735],\n",
       "        [1.9926, 7.4796, 0.7359]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weighted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 weighted_values의 shape은 (단어의 수 * 차원(value의 가로 길이))와 일치합니다.\n",
    "\n",
    "멀티 헤드 어텐션은 이 과정을 헤드의 수 만큼 진행합니다. \n",
    "\n",
    "weighted_values * H 를 하면 (단어의 수 * 차원) * (헤드의 개수)가 되고, \n",
    "\n",
    "여기에 W0을 matmul을 하면 된다. W0.shape = (헤드의 개수) * (차원)\n",
    "\n",
    "이 W0도 다른 Wq Wk Wv와 마찬가지로 태스크를 가장 잘 수행하는 방향으로 업데이트 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor([2,1])\n",
    "w1 = torch.tensor([ \n",
    "    [3,2,-4], \n",
    "    [2,-3,1]\n",
    "])\n",
    "b1 = 1 \n",
    "w2 = torch.tensor([ \n",
    "    [-1,1], \n",
    "    [1,2],\n",
    "    [3,1]\n",
    "])\n",
    "b2= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 계산을 수행하는 코드입니다.\n",
    "\n",
    "입력 x와 w1을 행렬곱한 뒤 b1을 더한 것이 h_preact입니다. \n",
    "\n",
    "여기에 Relu를 취해 은닉층 h를 만듭니다.\n",
    "\n",
    "마지막으로 h와 w2를 행렬곱한 뒤 b2를 더해 출력츨 y를 계산하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_preact = torch.matmul(x,w1)+b1\n",
    "h = torch.nn.functional.relu(h_preact)\n",
    "y = torch.matmul(h,w2)+b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이어 정규화\n",
    "\n",
    "레이어 정규화란 미니 배치의 인스턴스(x) 별로 평균을 빼주고, 표준편차로 나누어 정규화를 수행하는 기법입니다. \n",
    "\n",
    "레이어 정규화를 수행하면 학습이 안정되고 그 속도가 빨라지는 등의 효과 있다고 합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([[1.0,2.0,3.0],[1.0,1.0,1.0]])\n",
    "#배치 크기는 2, 피처의 차원 수는 3\n",
    "\n",
    "m = torch.nn.LayerNorm(input.shape[-1])\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2247,  0.0000,  1.2247],\n",
       "        [ 0.0000,  0.0000,  0.0000]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Dropout(p=0.2)\n",
    "\n",
    "input = torch.randn(1,10)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2738, -1.2282, -0.9771,  1.8165,  1.7545, -0.3581,  1.1253, -0.3127,\n",
       "         -0.3682, -0.3343]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3422, -1.5353, -0.0000,  2.2706,  0.0000, -0.4476,  1.4066, -0.3909,\n",
       "         -0.4603, -0.4178]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbacf2a9d2e876d097b37d768b1e7f504d43ac1a5c7cfa4c05142076e87a32d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflowstart': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
