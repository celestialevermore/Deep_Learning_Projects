{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Classification 구조 개요\n",
    "CNN = Feature Extractor + Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 필터(Filter)\n",
    "\n",
    "이미지 필터링은 다양한 수식을 적용하여 이미지를 이루고 있는 픽셀\n",
    "\n",
    "배열을 변경하여 이미지를 변형하는 것을 말한다. Original... Comic Book.... 픽셀을 변형(배열의 요소 값을 조금씩 미세하게 변형)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2 이미지 필터링 적용 예\n",
    "\n",
    "  Original -> blur \n",
    "  Original 3*3의 값이 모두 1이라고 치면 각각 1/9를 곱한 결과가 바로 Blurred 처리된 이미지가 된다.\n",
    "\n",
    "  보통 정방 행렬을 원본 이미지에 순차적으로 슬라이딩해가면서 새로운 픽셀값을 만들면서 적용\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3 Image 배열에 Convolution 연산 적용\n",
    "\n",
    "  예를 들어 6 * 6 행렬의 원본 이미지가 있으면, Filter 3* 3 크기의 필터와 Convolution 연산을 하여 연산 결과 4 * 4를  만들게 된다. \n",
    "\n",
    "  3 * 1 + 2 * 0 + 1 * (-1) + 1 * 1 + 3 * 0 + 5 * -1 + 3 * 1 + 2 * 0 + 2 * -1 을 한 결과인 -1을 출력.\n",
    "\n",
    "  즉, 원본 이미지 * (3*3 Filter) = (4*4 Convolved Feature)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Filter에 Padding을 도입\n",
    "\n",
    "기존에는 5 * 5 원본 이미지가 있으면 3 * 3 FIlter를 Convolution 시켜 3 * 3을 만들었다면\n",
    "\n",
    "일부러 이 5 * 5 원본 이미지의 둘레에 0으로 쭉 둘러 7 * 7 패딩 원본 이미지를 만들고\n",
    "\n",
    "3 * 3 Filter를 통과시켜 5 * 5 feature maps1을 만들게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Filter와 Kernel의 구분\n",
    "\n",
    "CNN에서 Filter와 Kernel은 거의 혼용되어서 사용됩니다. \n",
    "\n",
    "하지만 명확히 구분하자면\n",
    "\n",
    "Filter는 여러 개의 Kernel로 구성되어 있으며!! 개별 Kernel은 필터 내에서 서로 다른 값을 가질 수 있습니다. \n",
    "\n",
    "\n",
    "conv_out_01 = Conv2D(filters=32,kernel_size=3)(input_tensor)\n",
    "\n",
    "의 의미는, 정방행렬의 크기가 3 * 3이고, 이 filter 32개를 적용하겠다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Kernel Size 특징\n",
    "\n",
    "Convolution Filter를 Kernel로도 지칭한다. 가로 세로 연구소(?)\n",
    "\n",
    "Kernel Size(크기)는 정방 행렬의 면적(Kernel Size * Kernel Size)를 의미 보통은 거의 가로 세로가 일치합니다. \n",
    "\n",
    "Kernel 크기가 크면 클 수록 입력 Feature Map(혹은 원본 이미지)에서 더 큰(또는 더 많은) Feature 정보를 가져올 수 있다. 덜 구체적? 캐시 크기가 커지면 의미가 덜 한 것처럼.\n",
    "\n",
    "하지만 큰 사이즈의 Kernel로 Convolution 연산을 할 경우 훨씬 더 많은 연산량과 파라미터가 필요합니다. 더 많은 통과를 해야함;\n",
    "\n",
    "Filter의 행렬값 하나하나가 Parameter라고 보면 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러니까 Kernel Size가 커지면 한 층을 통과할 때마다의 연산량도 줄고, 인간의 뇌로 따지면 하나의 뉴런이 담당하는 크기가 크지만,\n",
    "\n",
    "결과적으로는 더 많은 층 연산이 필요하다는 단점으로 귀결됨.\n",
    "\n",
    "Receptive Field : 입력(Image(0차), Feature Map(N차)에서 feature를 만드는 영역의 기본 크기) : 뉴런 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Feature Map\n",
    "\n",
    "결국 Convolution Layer를 통과할 때마다 등장하는 결과라고 보면 된다.\n",
    "\n",
    "Input image -> Feature map1 ... Feauture mapN -> Fully Connected Map으로 넘어가게 된다.\n",
    "\n",
    "예)\n",
    "\n",
    "conv_out_01 = Conv2D(filters=32,kernel_size=3)(input_tensor)\n",
    "\n",
    "\n",
    "가 있으면 Input layer를 통과하여 만들어지는 feature maps의 개수가 32개이고, 하나의 크기가 3 * 3 이라는 뜻임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Deep Learning CNN 에서의 FIlter 값 결정\n",
    "\n",
    "일반적으로 Vision 에서 filter는 사용자가 목적에 맞는 특정 필터를 스스로 만들거나, 기존에 설계된 다양한 필터를 선택하여 이미지에 적용\n",
    "\n",
    "\n",
    "Deep Learning CNN은 Filter 값을 사용자가 만들거나, 선택할 필요 없습니다. Random으로 간다. \n",
    "\n",
    "Deep Learning Network 구성을 통해 이미지 분류 등의 목적에 부합하는 최적의 filter값을 학습을 통해 \n",
    "\n",
    "스스로 최적화한다. \n",
    "\n",
    "Filter 값들도 전부 Back Propagation에서 Update가 이루어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stride 개요\n",
    "\n",
    "Stride는 입력 데이터(원본 image(0차), 입력 feature map(n차))에 Conv Filter를 적용할 때 Sliding Window가 이동하는 간격을 의미!!\n",
    "\n",
    "Case 1) (7 * 7) 입력 Volume이 있고, (3 * 3) Filter를 한칸씩 움직이는 경우 -> 5 * 5 Feature maps가 출력\n",
    "\n",
    "Case 2) (7 * 7) 입력 Volume이 있고, (3 * 3) Filter를 두 칸씩 움직이는 경우 -> 3 * 3 Feature maps가 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 간격을 더 크게 하면 대충대충? 연산하게 될 것 같지만 꼭 그렇지는 않음.\n",
    "\n",
    "기본은 1이지만 2로 적용하여 입력 feature map 대비 출력 feature map의 크기를 대략 절반으로 줄임!\n",
    "\n",
    "Stride를 키우면 공간적인 feature 특성을 손실할 가능성은 높아지지만, 즉 이전 layer의 정보를 상대적으로 제한적으로 다음 layer로 전달\n",
    "\n",
    "이것이 중요 feature들의 손실을 반드시 의미하지는 않음. \n",
    "\n",
    "오히려 불필요한 특성을 제거하는 효과를 가져올 수 있음!! \n",
    "\n",
    "또한 Convolution 연산 속도를 향상 시킴.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### padding 개요\n",
    "\n",
    "Filter를 적용하여 Conv 연산을 할 때 출력 N+1번째 출력 Feature Map이 N번째 입력 Feature Map 대비 계속적으로 작아지는 것을 막기 위해 사용\n",
    "\n",
    "Filter 적용 전 보존하려는 Feature Map 크기에 맞게 입력 Feature Map의 좌우 끝과 상하 끝에 각각 열과 행을 추가한 뒤, 0값을 채워서 \n",
    "\n",
    "N번째 입력 Feature Map 사이즈를 증가시킵니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding 특징\n",
    "\n",
    "CNN Network가 깊어질수록, 즉 Conv 연산을 많이하면 많이할수록 Feature Map의 크기가 무분별하게 줄어드는 현상을 막을 수 있다.\n",
    "\n",
    "모서리 주변의 Conv 연산 횟수가 증가되어 모서리 주변 feature들의 특징을 보다 강화하는 장점이 생기게 됩니다. \n",
    "\n",
    "Zero Padding의 영향으로 모서리 주변의 0값이 같이 입력되어 Noise가 증가하는 우려도 있음.\n",
    "\n",
    "Keras에서 Conv2D()의 인자로 padding = 'same'을 넣어주면 Conv 연산 시 자동으로 \n",
    "\n",
    "N번째 입력 Feature Map의 크기를 N+1번째 Feature map에서 유지할 수 있게 padding 면적을 계산하여 적용합니다.\n",
    "\n",
    "한편 padding='valid'를 적용하면 별도의 padding을 적용하지 않고 Conv 연산을 수행합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2D 적용하기\n",
    "\n",
    "COnv2D() 모델에 적용 시에는 반드시 입력은 배치 크기를 제외하고 3차원!이 되어야 함.\n",
    "\n",
    "즉 배치를 포함하면 4차원이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type : <class 'keras.engine.keras_tensor.KerasTensor'> x : KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 4), dtype=tf.float32, name=None), name='conv2d/Relu:0', description=\"created by layer 'conv2d'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:01:45.329434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.329532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.329597: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.384200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.384300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.384377: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-12-05 20:01:45.384394: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-05 20:01:45.385033: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D \n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "input_tensor = Input(shape=(28,28,1))\n",
    "#fashion mnist 때에는 2차원이지만, 이제는 3차원입니다. \n",
    "#Conv2d는 Batch를 제외한 Input이 무조건 3차원이 됩니다.\n",
    "\n",
    "x = Conv2D(filters=4,kernel_size=3,strides=1,padding='same',activation='relu')(input_tensor)\n",
    "\n",
    "print('x type :',type(x), 'x :',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b45cb9130eebfe057782ef3fcf20eb5ae5c81aa7ea2b32ada9dc8e4e9a15b7c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
